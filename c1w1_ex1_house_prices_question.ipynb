{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27edea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 14:23:11.673384: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-09 14:23:12.026769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f407444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  9 14:24:27 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Graphics...  On   | 00000000:01:00.0 Off |                  Off |\r\n",
      "|  0%   40C    P2    78W / 450W |   4032MiB / 24564MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      3605      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    0   N/A  N/A     17426      C   ...safi/anaconda3/bin/python     2012MiB |\r\n",
      "|    0   N/A  N/A     17712      C   ...safi/anaconda3/bin/python     2012MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd241202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "gpu = len(tf.config.list_physical_devices(\"GPU\")) > 0\n",
    "print(\"GPU is\", \"available\" if gpu else \"not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc43f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f153007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def house_model(y_new):\n",
    "    xs = np.array([1, 2, 3, 4, 5])\n",
    "    ys = np.array([1., 1.5, 2., 2.5, 3.])\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(units = 1, input_shape = [1])\n",
    "    ])\n",
    "    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "    model.fit(xs, ys, epochs = 1000, verbose = False)\n",
    "    return model.predict(y_new)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570b5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 14:23:18.012871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-07-09 14:23:18.586619: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fefee352220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-09 14:23:18.586630: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Graphics Device, Compute Capability 8.9\n",
      "2023-07-09 14:23:18.697284: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-07-09 14:23:18.742371: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-09 14:23:18.789479: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = house_model([7.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8dfb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.006323]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0772b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
